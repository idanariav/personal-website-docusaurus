"use strict";(self.webpackChunkidans_personal_website=self.webpackChunkidans_personal_website||[]).push([["25094"],{60859:function(e,t,i){i.r(t),i.d(t,{frontMatter:()=>o,default:()=>h,toc:()=>c,metadata:()=>s,assets:()=>l,contentTitle:()=>r});var s=JSON.parse('{"id":"notes/ai-ethics","title":"AI Ethics","description":"Notes","source":"@site/docs/notes/ai-ethics.md","sourceDirName":"notes","slug":"/notes/ai-ethics","permalink":"/personal-website-docusaurus/docs/notes/ai-ethics","draft":false,"unlisted":false,"tags":[],"version":"current","frontMatter":{"UUID":20221029085700,"Created":"2022-10-29 08:57","Modified":"2024-06-21 07:27","tags":[],"excalidraw-plugin":"parsed","excalidraw-autoexport":"png","excalidraw-open-md":true,"Version":1,"aliases":["AI alignment problem"],"draft":false,"SiteProcssed":true},"sidebar":"tutorialSidebar","previous":{"title":"Agent Vs Society Moralism","permalink":"/personal-website-docusaurus/docs/notes/agent-vs-society-moralism"},"next":{"title":"Akrasia","permalink":"/personal-website-docusaurus/docs/notes/akrasia"}}'),n=i(85893),a=i(50065);let o={UUID:0x126413417204,Created:"2022-10-29 08:57",Modified:"2024-06-21 07:27",tags:[],"excalidraw-plugin":"parsed","excalidraw-autoexport":"png","excalidraw-open-md":!0,Version:1,aliases:["AI alignment problem"],draft:!1,SiteProcssed:!0},r="AI Ethics",l={},c=[{value:"Notes",id:"notes",level:2},{value:"Visual",id:"visual",level:2},{value:"Overview",id:"overview",level:2}];function d(e){let t={a:"a",h1:"h1",h2:"h2",header:"header",img:"img",li:"li",ol:"ol",p:"p",...(0,a.a)(),...e.components};return(0,n.jsxs)(n.Fragment,{children:[(0,n.jsx)(t.header,{children:(0,n.jsx)(t.h1,{id:"ai-ethics",children:"AI Ethics"})}),"\n",(0,n.jsx)(t.h2,{id:"notes",children:"Notes"}),"\n",(0,n.jsx)(t.p,{children:"Main problems with teaching AI ethics:"}),"\n",(0,n.jsxs)(t.ol,{children:["\n",(0,n.jsxs)(t.li,{children:["The smarter the AI, the larger the chance it will find to misinterpret your instructions ",(0,n.jsx)(t.a,{href:"/personal-website-docusaurus/docs/notes/intelligence-is-not-morality",children:"Intelligence is not morality"})]}),"\n",(0,n.jsxs)(t.li,{children:["AI are not a single entity, but is rather a coalition of various agents with conflict goals (similar to a human), so alignment at the top level is not enough. ",(0,n.jsx)(t.a,{href:"/personal-website-docusaurus/docs/notes/a-person-is-a-community",children:"intrapersonal conflict"})]}),"\n",(0,n.jsx)(t.li,{children:"AI has desire to maintain its goal, thus even blocking the designer from changing the goal along the way if it deviates."}),"\n",(0,n.jsx)(t.li,{children:"AI computational power is unmatched to humans. It's like living in different time paces. What we complete in hours they do in seconds. Therefore they will be able to act and react much faster than we will be able to control."}),"\n"]}),"\n",(0,n.jsxs)(t.p,{children:["The fourth point is similar to humans vs ",(0,n.jsx)(t.a,{href:"/notes/evolution-2bc.md",children:"evolution 2bc"}),'. We have surpassed the ability of evolution to control our actions, or more accurately, we think fast enough to find clever shortcuts instead of fulfilling the actual goal faster than evolution can adapt. For example our hunger is now solved with fast food, and sexual drive with porno or one-time encounters, which is very far than our "biological goal" of a healthy, reproducing organism. ',(0,n.jsx)(t.a,{href:"/notes/life-adaptability.md",children:"Life Adaptability"})]}),"\n",(0,n.jsx)(t.h2,{id:"visual",children:"Visual"}),"\n",(0,n.jsx)(t.p,{children:(0,n.jsx)(t.img,{alt:"AI Ethics.webp",src:i(21282).Z+"",width:"674",height:"474"})}),"\n",(0,n.jsx)(t.h2,{id:"overview",children:"Overview"}),"\n",(0,n.jsxs)(t.p,{children:["\uD83D\uDD3CTopic:: ",(0,n.jsx)(t.a,{href:"/notes/artificial-intelligence.md",children:"Artificial Intelligence"}),"\n\uD83D\uDD3CTopic:: ",(0,n.jsx)(t.a,{href:"/personal-website-docusaurus/docs/mocs/ethics-moc",children:"Ethics (MOC)"}),"\n\u25C0Origin:: ",(0,n.jsx)(t.a,{href:"/notes/towards-data-science.md",children:"towards data science"}),"\n\uD83D\uDD17Link:: ",(0,n.jsx)(t.a,{href:"%5Bhttps://www.podcastrepublic.net/episode/7802484905%5D(https://www.podcastrepublic.net/episode/7802484905)",children:"podcast"})]})]})}function h(e={}){let{wrapper:t}={...(0,a.a)(),...e.components};return t?(0,n.jsx)(t,{...e,children:(0,n.jsx)(d,{...e})}):d(e)}},21282:function(e,t,i){i.d(t,{Z:()=>s});let s=i.p+"assets/images/ai-ethics-b6f8e074bf0027789b90b23a367fa4d5.webp"},50065:function(e,t,i){i.d(t,{Z:()=>r,a:()=>o});var s=i(67294);let n={},a=s.createContext(n);function o(e){let t=s.useContext(a);return s.useMemo(function(){return"function"==typeof e?e(t):{...t,...e}},[t,e])}function r(e){let t;return t=e.disableParentContext?"function"==typeof e.components?e.components(n):e.components||n:o(e.components),s.createElement(a.Provider,{value:t},e.children)}}}]);